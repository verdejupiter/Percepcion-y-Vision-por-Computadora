{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e4b92e0b",
   "metadata": {},
   "source": [
    "<h3 style=\"text-align:center\" style=\"color:rgb(0,0,255);\">UNIVERSIDAD NACIONAL DE TRUJILLO</h3>\n",
    "<h3 style=\"text-align:center\" style=\"color:rgb(0,0,255);\">FACULTAD DE CIENCIAS FÍSICAS Y MATEMÁTICAS</h3>\n",
    "<h3 style=\"text-align:center\" style=\"color:rgb(0,0,255);\">ESCUELA PROFESIONAL DE INFORMÁTICA</h3>\t\n",
    "<img src=\"UNT.png\" width=\"300\" height=\"135\" align=\"middle\">\n",
    "<h3 style=\"text-align:center\" style=\"color:rgb(0,0,255);\">PROYECTO:</h3>\n",
    "<h3 style=\"text-align:center\" style=\"color:rgb(0,0,255);\">Identificación de Xanthomonas oryzae pv.\n",
    "oryzicola (bacterial leaf blight of rice) en las hojas de arroz mediante visión por computador</h3>\n",
    "<h3 style=\"text-align:center\" style=\"color:rgb(0,0,255);\">CURSO:</h3>\n",
    "<h3 style=\"text-align:center\" style=\"color:rgb(0,0,255);\">Percepción y Visión por Computadoras</h3>\n",
    "<h3 style=\"text-align:center\" style=\"color:rgb(0,0,255);\">ESTUDIANTES:</h3>\n",
    "<h3 style=\"text-align:center\" style=\"color:rgb(0,0,255);\">-Mendez Cruz, Angely Yahayra</h3>\n",
    "<h3 style=\"text-align:center\" style=\"color:rgb(0,0,255);\">-Mendez Cruz, Ciara Solange</h3>\n",
    "<h3 style=\"text-align:center\" style=\"color:rgb(0,0,255);\">DOCENTE:</h3>\n",
    "<h3 style=\"text-align:center\" style=\"color:rgb(0,0,255);\">Dra. Ing. Pedro Huaman Liz Sofia Raymunda</h3>\n",
    "<h3 style=\"text-align:center\" style=\"color:rgb(0,0,255);\">Trujillo - Perú</h3>\n",
    "<h3 style=\"text-align:center\" style=\"color:rgb(0,0,255);\">2023</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9eacf8",
   "metadata": {},
   "source": [
    "<h1 style=\"color:RGB(0,0,255)\"> 1. Instalación de librerías </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a80139f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\usuario\\anaconda3\\envs\\angely_enviromet\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\usuario\\anaconda3\\envs\\angely_enviromet\\lib\\site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\usuario\\anaconda3\\envs\\angely_enviromet\\lib\\site-packages (from scikit-learn) (1.24.2)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\usuario\\anaconda3\\envs\\angely_enviromet\\lib\\site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\usuario\\anaconda3\\envs\\angely_enviromet\\lib\\site-packages (from scikit-learn) (3.1.0)\n",
      "Requirement already satisfied: mahotas in c:\\users\\usuario\\anaconda3\\envs\\angely_enviromet\\lib\\site-packages (1.4.13)\n",
      "Requirement already satisfied: numpy in c:\\users\\usuario\\anaconda3\\envs\\angely_enviromet\\lib\\site-packages (from mahotas) (1.24.2)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\usuario\\anaconda3\\envs\\angely_enviromet\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: packaging>=21 in c:\\users\\usuario\\anaconda3\\envs\\angely_enviromet\\lib\\site-packages (from scikit-image) (23.0)\n",
      "Requirement already satisfied: scipy>=1.8 in c:\\users\\usuario\\anaconda3\\envs\\angely_enviromet\\lib\\site-packages (from scikit-image) (1.10.1)\n",
      "Requirement already satisfied: pillow>=9.0.1 in c:\\users\\usuario\\anaconda3\\envs\\angely_enviromet\\lib\\site-packages (from scikit-image) (9.4.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\usuario\\anaconda3\\envs\\angely_enviromet\\lib\\site-packages (from scikit-image) (2023.4.12)\n",
      "Requirement already satisfied: networkx>=2.8 in c:\\users\\usuario\\anaconda3\\envs\\angely_enviromet\\lib\\site-packages (from scikit-image) (3.1)\n",
      "Requirement already satisfied: numpy>=1.21.1 in c:\\users\\usuario\\anaconda3\\envs\\angely_enviromet\\lib\\site-packages (from scikit-image) (1.24.2)\n",
      "Requirement already satisfied: imageio>=2.27 in c:\\users\\usuario\\anaconda3\\envs\\angely_enviromet\\lib\\site-packages (from scikit-image) (2.28.1)\n",
      "Requirement already satisfied: lazy_loader>=0.2 in c:\\users\\usuario\\anaconda3\\envs\\angely_enviromet\\lib\\site-packages (from scikit-image) (0.2)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in c:\\users\\usuario\\anaconda3\\envs\\angely_enviromet\\lib\\site-packages (from scikit-image) (1.4.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn\n",
    "!pip install mahotas\n",
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2024aeac",
   "metadata": {},
   "source": [
    "<h1 style=\"color:RGB(0,0,255)\"> 2. Importación de librerías </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2a0f3757",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "#Segmentación\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "#Extracción de Características\n",
    "import mahotas.features.texture as texture\n",
    "from skimage.measure import label, regionprops\n",
    "#Clasificador\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "# Matriz de Confusión\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import pickle\n",
    "#Grid Search\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b6f522",
   "metadata": {},
   "source": [
    "<h1 style=\"color:RGB(0,0,255)\"> 3. Adquisición de Imagen (Datasets: CABY Digital Library y Kaggle)</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1e12db79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directorio de la dataset\n",
    "dataset_dir = './data'\n",
    "\n",
    "# Tamaño deseado para las imágenes\n",
    "desired_size = (512, 512)\n",
    "\n",
    "# Rutas de las carpetas de cada categoría\n",
    "enfermas_dir = os.path.join(dataset_dir, 'enfermas')\n",
    "sanas_dir = os.path.join(dataset_dir, 'sanas')\n",
    "# otras_plagas_dir = os.path.join(dataset_dir, 'otras_plagas')\n",
    "\n",
    "# Leer las imágenes de cada categoría\n",
    "enfermas_images = []\n",
    "for filename in os.listdir(enfermas_dir):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(enfermas_dir, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, desired_size)\n",
    "        enfermas_images.append(image)\n",
    "\n",
    "sanas_images = []\n",
    "for filename in os.listdir(sanas_dir):\n",
    "    if filename.endswith('.jpg'):\n",
    "        image_path = os.path.join(sanas_dir, filename)\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.resize(image, desired_size)        \n",
    "        sanas_images.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9616f2c2",
   "metadata": {},
   "source": [
    "<h1 style=\"color:RGB(0,0,255)\"> 4. Preprocesamiento de imagen</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a652fc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mostrar Resultados \n",
    "# plt.figure(figsize=(13,5))\n",
    "\n",
    "def preprocess_image(image):\n",
    "           \n",
    "#     plt.subplot(1,5,1)\n",
    "#     plt.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))\n",
    "#     plt.title('Imagen original',fontsize=7)\n",
    "#     plt.axis(\"off\")\n",
    "    \n",
    "    # Convertir la imagen a espacio de color HSV\n",
    "    hsv_image = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n",
    "    \n",
    "#     plt.subplot(1,5,2)\n",
    "#     plt.imshow(hsv_image)\n",
    "#     plt.title('Imagen en espacio de color HSV',fontsize=7)\n",
    "#     plt.axis(\"off\")\n",
    "\n",
    "    # Extraer el componente S de la imagen\n",
    "    s_component = hsv_image[:, :, 1]\n",
    "\n",
    "    # Aplicar un umbral para convertir el componente S en binario\n",
    "    _, binary_image = cv2.threshold(s_component, 0.28 * 255, 255, cv2.THRESH_BINARY)\n",
    "\n",
    "    # Crear una máscara con el fondo negro\n",
    "    mask = cv2.merge((binary_image, binary_image, binary_image))\n",
    "    \n",
    "#     plt.subplot(1,5,3)\n",
    "#     plt.imshow(mask)\n",
    "#     plt.title('Máscara con fondo negro',fontsize=7)\n",
    "#     plt.axis(\"off\")\n",
    "\n",
    "    # Extraer los componentes R, G, B de la imagen original\n",
    "    r_component, g_component, b_component = cv2.split(image)\n",
    "\n",
    "    # Aplicar la máscara a cada componente individualmente\n",
    "    r_masked = cv2.bitwise_and(r_component, mask[:, :, 0])\n",
    "    g_masked = cv2.bitwise_and(g_component, mask[:, :, 1])\n",
    "    b_masked = cv2.bitwise_and(b_component, mask[:, :, 2])\n",
    "\n",
    "    # Combinar los componentes enmascarados en una nueva imagen\n",
    "    masked_image = cv2.merge((r_masked, g_masked, b_masked))\n",
    "    \n",
    "#     plt.subplot(1,5,4)\n",
    "#     plt.imshow(cv2.cvtColor(masked_image,cv2.COLOR_BGR2RGB))\n",
    "#     plt.title('Imagen sin fondo',fontsize=7)\n",
    "#     plt.axis(\"off\")    \n",
    "    \n",
    "    # Aplicar un filtro de media para reducir el ruido\n",
    "    filtered_image = cv2.boxFilter(masked_image, -1, (5, 5))\n",
    "    \n",
    "#     plt.subplot(1,5,5)\n",
    "#     plt.imshow(cv2.cvtColor(filtered_image,cv2.COLOR_BGR2RGB))\n",
    "#     plt.title('Imagen sin ruido',fontsize=7)\n",
    "#     plt.axis(\"off\")    \n",
    "#     plt.show()\n",
    "\n",
    "    return filtered_image\n",
    "\n",
    "# Resultados \n",
    "# image_path = \"./data/enfermas/bacterial_leaf_blight (121).JPG\"\n",
    "# image = cv2.imread(image_path)\n",
    "# pre_img= preprocess_image(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e636ba",
   "metadata": {},
   "source": [
    "<h1 style=\"color:RGB(0,0,255)\"> 5. Segmentación de imagen</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e0ab1aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(13,5))\n",
    "\n",
    "def segment_image(filtered_image):\n",
    "    \n",
    "#     plt.subplot(1,5,1)\n",
    "#     plt.imshow(cv2.cvtColor(filtered_image,cv2.COLOR_BGR2RGB))\n",
    "#     plt.title('Imagen Preprocesada',fontsize=7)\n",
    "#     plt.axis(\"off\")\n",
    "\n",
    "    # Convertir la imagen sin fondo al espacio de color HSV\n",
    "    hsv_image = cv2.cvtColor(filtered_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Extraer el componente Hue de la imagen en el espacio de color HSV\n",
    "    hue_component = hsv_image[:, :, 0]\n",
    "\n",
    "    # Obtener las dimensiones de la imagen del componente Hue\n",
    "    rows, cols = hue_component.shape\n",
    "\n",
    "    # Transformar la imagen del componente Hue en un vector\n",
    "    hue_vector = hue_component.reshape(-1)\n",
    "\n",
    "    # Aplicar K-means en el componente Hue con #clusters = 3\n",
    "    kmeans = KMeans(n_clusters=3, n_init=10, random_state=0)\n",
    "    kmeans.fit(hue_vector.reshape(-1, 1))\n",
    "\n",
    "    # Etiquetar cada píxel en la imagen de fondo eliminada usando el resultado de K-means\n",
    "    segmented_image = kmeans.labels_.reshape(rows, cols)\n",
    "\n",
    "    # Crear tres imágenes vacías de la misma dimensión para almacenar el resultado de la agrupación\n",
    "    cluster1_image = np.zeros((rows, cols, 3), dtype=np.uint8)\n",
    "    cluster2_image = np.zeros((rows, cols, 3), dtype=np.uint8)\n",
    "    cluster3_image = np.zeros((rows, cols, 3), dtype=np.uint8)\n",
    "\n",
    "    # Asignar cada píxel a la imagen respectiva en función de la detección de etiqueta/índice asignada\n",
    "    \n",
    "   # Obtener los colores originales de la imagen de entrada\n",
    "    colors = filtered_image.reshape(-1, 3)\n",
    "\n",
    "    # Asignar los colores originales a cada píxel en las imágenes segmentadas\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            if segmented_image[i, j] == 0:\n",
    "                cluster1_image[i, j] = colors[i * cols + j]\n",
    "            elif segmented_image[i, j] == 1:\n",
    "                cluster2_image[i, j] = colors[i * cols + j]\n",
    "            elif segmented_image[i, j] == 2:\n",
    "                cluster3_image[i, j] = colors[i * cols + j]\n",
    "                               \n",
    "#     plt.subplot(1,5,2)\n",
    "#     plt.imshow(cv2.cvtColor(cluster1_image,cv2.COLOR_BGR2RGB))\n",
    "#     plt.title('Cluster 1: Fondo',fontsize=7)\n",
    "#     plt.axis(\"off\")\n",
    "    \n",
    "#     plt.subplot(1,5,3)\n",
    "#     plt.imshow(cv2.cvtColor(cluster2_image,cv2.COLOR_BGR2RGB))\n",
    "#     plt.title('Cluster 2: Parte Sana',fontsize=7)\n",
    "#     plt.axis(\"off\")\n",
    "    \n",
    "#     plt.subplot(1,5,4)\n",
    "#     plt.imshow(cv2.cvtColor(cluster3_image,cv2.COLOR_BGR2RGB))\n",
    "#     plt.title('Cluster 3: Parte Enferma',fontsize=7)\n",
    "#     plt.axis(\"off\")\n",
    "\n",
    "    enferma_image= cluster3_image\n",
    "    # Convertir la imagen de la parte enferma al espacio de color HSV\n",
    "    hsv_enferma = cv2.cvtColor(enferma_image, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Definir los valores mínimo y máximo para el rango de color verde\n",
    "    min_green = 17.2 / 360   # Convertir a escala de 0 a 1\n",
    "    max_green = 45 / 360     # Convertir a escala de 0 a 1\n",
    "\n",
    "    # Crear una máscara binaria basada en el rango de color verde para la parte enferma\n",
    "    mask = cv2.inRange(hsv_enferma, (min_green, 0, 0), (max_green, 255, 255))\n",
    "\n",
    "    # Aplicar la máscara a la imagen de la parte enferma para eliminar la porción verde\n",
    "    enferma_sin_verde = cv2.bitwise_and(enferma_image, enferma_image, mask=cv2.bitwise_not(mask))\n",
    "\n",
    "#     plt.subplot(1,5,5)\n",
    "#     plt.imshow(cv2.cvtColor(enferma_sin_verde,cv2.COLOR_BGR2RGB))\n",
    "#     plt.title('Sin Porción Verde',fontsize=7)\n",
    "#     plt.axis(\"off\") \n",
    "#     plt.show()     \n",
    "    \n",
    "    return cluster1_image, cluster2_image, enferma_sin_verde\n",
    "\n",
    "# enferma_sin_verde = segment_image(pre_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "840d641e",
   "metadata": {},
   "source": [
    "<h1 style=\"color:RGB(0,0,255)\"> 6. Extracción de Características</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7e39246e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(enferma_image):\n",
    "    \n",
    "    # Convertir la imagen a escala de grises\n",
    "    enferma_gray = cv2.cvtColor(enferma_image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Extraer características de color\n",
    "    r_mean = np.mean(enferma_image[:, :, 2])\n",
    "    g_mean = np.mean(enferma_image[:, :, 1])\n",
    "    b_mean = np.mean(enferma_image[:, :, 0])\n",
    "    r_std = np.std(enferma_image[:, :, 2])\n",
    "    g_std = np.std(enferma_image[:, :, 1])\n",
    "    b_std = np.std(enferma_image[:, :, 0])\n",
    "\n",
    "    # Extraer características de forma\n",
    "    enferma_mask = cv2.threshold(enferma_gray, 0.28, 1, cv2.THRESH_BINARY)[1]\n",
    "    total_area = np.sum(enferma_mask)\n",
    "    labeled_image = label(enferma_mask)\n",
    "    num_spots = len(np.unique(labeled_image)) - 1\n",
    "\n",
    "    # Extraer características de textura utilizando mahotas\n",
    "    mahotas_glcm = texture.haralick(enferma_gray)\n",
    "    mahotas_contrast = mahotas_glcm.mean(axis=0)[2]\n",
    "    mahotas_correlation = mahotas_glcm.mean(axis=0)[4]\n",
    "    mahotas_energy = mahotas_glcm.mean(axis=0)[8]\n",
    "    mahotas_homogeneity = mahotas_glcm.mean(axis=0)[1]\n",
    "\n",
    "    # Crear vector de características\n",
    "    features85 = [\n",
    "        r_mean, g_mean, b_mean, r_std, g_std, b_std,\n",
    "        total_area, num_spots, \n",
    "        mahotas_contrast, mahotas_correlation, mahotas_energy, mahotas_homogeneity\n",
    "    ]\n",
    "\n",
    "    return features85\n",
    "\n",
    "# extract_features(enferma_sin_verde)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ee23f6",
   "metadata": {},
   "source": [
    "<h1 style=\"color:RGB(0,0,255)\"> 7. Clasificación de imágenes</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36001f7f",
   "metadata": {},
   "source": [
    "<h2 style=\"color:RGB(0,0,0)\"> 7.1 Agregar Características y etiquetas a cada clase</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "5c2035a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# las características extraídas para múltiples imágenes\n",
    "# Guarda las características en una lista\n",
    "features = []\n",
    "\n",
    "# Guarda las etiquetas correspondientes a las características en una lista\n",
    "labels = []\n",
    "\n",
    "# Agrega las características y etiquetas de cada imagen a las listas\n",
    "# Clase 1 - Imágenes\n",
    "for img in enfermas_images:\n",
    "    preprocessed_image = preprocess_image(img)\n",
    "    _,_,segmented_image = segment_image(preprocessed_image)\n",
    "    r_features = extract_features(segmented_image)\n",
    "    # Agregar las características a la lista features\n",
    "    features.append(r_features)\n",
    "    labels.append(0)  # Etiqueta correspondiente a la clase de la imagen\n",
    "\n",
    "# Clase 2 - Imágenes\n",
    "for img in sanas_images:\n",
    "    preprocessed_image = preprocess_image(img)\n",
    "    _,_,segmented_image = segment_image(preprocessed_image)\n",
    "    r_features = extract_features(segmented_image)\n",
    "    # Agregar las características a la lista features\n",
    "    features.append(r_features)\n",
    "    labels.append(1)  # Etiqueta correspondiente a la clase de la imagen\n",
    "\n",
    "# Determinar la longitud máxima de las características\n",
    "max_length = max(len(f) for f in features)\n",
    "\n",
    "# Rellenar o truncar las características para que tengan la misma longitud\n",
    "for i in range(len(features)):\n",
    "    if len(features[i]) < max_length:\n",
    "        features[i] = features[i] + [0] * (max_length - len(features[i]))\n",
    "    else:\n",
    "        features[i] = features[i][:max_length]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "256e5798",
   "metadata": {},
   "source": [
    "<h2 style=\"color:RGB(0,0,0)\"> 7.2 Clasificador SVM </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "632866fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicciones: [1 1 1 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Precisión: 0.9607843137254902\n"
     ]
    }
   ],
   "source": [
    "# Convertir las listas de características y etiquetas en arreglos de NumPy\n",
    "X = np.array(features)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "# Asegurarse de que las características sean de tipo float si es necesario\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "\n",
    "# Crea un clasificador SVM para clasificación binaria\n",
    "\n",
    "# clf = svm.SVC(C=1, kernel=\"linear\", probability=True)\n",
    "clf = svm.SVC(C=0.1, gamma='scale', kernel='linear', probability=True)\n",
    "\n",
    "# Entrena el clasificador SVM utilizando los datos de entrenamiento\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "#Guardar clasificador entrenado\n",
    "with open('./SVC_model.pkl', 'wb') as f:\n",
    "    pickle.dump(clf, f)\n",
    "\n",
    "# Realiza predicciones en los datos de prueba\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "# Evalúa el desempeño del clasificador\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "\n",
    "# Imprime las predicciones y la precisión del clasificador\n",
    "print(\"Predicciones:\", predictions)\n",
    "print(\"Precisión:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be83a8c",
   "metadata": {},
   "source": [
    "<h2 style=\"color:RGB(0,0,0)\"> 7.2.1 Búsqueda de rejilla con validación cruzada </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d01bd6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores hiperparámetros: {'C': 0.1, 'gamma': 'scale', 'kernel': 'linear'}\n",
      "Mejor precisión: 0.97\n"
     ]
    }
   ],
   "source": [
    "# Convertir las listas de características y etiquetas en arreglos de NumPy\n",
    "X = np.array(features)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Divide los datos en conjuntos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Asegurarse de que las características sean de tipo float si es necesario\n",
    "X_train = X_train.astype(float)\n",
    "X_test = X_test.astype(float)\n",
    "\n",
    "# Crea un clasificador SVM para clasificación binaria\n",
    "clf = svm.SVC()\n",
    "\n",
    "# Define la cuadrícula de valores para los hiperparámetros a probar\n",
    "param_grid = {\n",
    "    'C': [0.1, 1, 10, 50, 100],\n",
    "    'kernel': ['linear', 'rbf'],\n",
    "    'gamma': ['scale', 'auto']\n",
    "}\n",
    "\n",
    "# Crea el objeto GridSearchCV con validación cruzada\n",
    "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Realiza la búsqueda de hiperparámetros utilizando los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Obtiene la mejor combinación de hiperparámetros y la mejor métrica de evaluación\n",
    "best_params = grid_search.best_params_\n",
    "best_score = grid_search.best_score_\n",
    "\n",
    "# Imprime los resultados\n",
    "print(\"Mejores hiperparámetros:\", best_params)\n",
    "print(\"Mejor precisión:\", best_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e2b6c76",
   "metadata": {},
   "source": [
    "<h2 style=\"color:RGB(0,0,0)\"> 7.2.2 Matriz de Confusión </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "bc7d84fc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz de confusión:\n",
      "[[ 2  0]\n",
      " [ 2 47]]\n",
      "Reporte de clasificación:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      1.00      0.67         2\n",
      "           1       1.00      0.96      0.98        49\n",
      "\n",
      "    accuracy                           0.96        51\n",
      "   macro avg       0.75      0.98      0.82        51\n",
      "weighted avg       0.98      0.96      0.97        51\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('./SVC_model.pkl', 'rb') as f:\n",
    "    clf= pickle.load(f)\n",
    "\n",
    "# Realiza predicciones en los datos de prueba\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "# Obtén la matriz de confusión\n",
    "confusion_mat = confusion_matrix(y_test, predictions)\n",
    "print(\"Matriz de confusión:\")\n",
    "print(confusion_mat)\n",
    "\n",
    "# Calcula la precisión, recall y F1-score\n",
    "classification_rep = classification_report(y_test, predictions)\n",
    "print(\"Reporte de clasificación:\")\n",
    "print(classification_rep)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4ba5698",
   "metadata": {},
   "source": [
    "<h1 style=\"color:RGB(0,0,255)\"> 8. Identificación de la Plaga</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4e097b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase predicha: [0]\n",
      "Muestra 1:\n",
      "Probabilidad clase sana: 4.44942915178412e-05\n",
      "Probabilidad clase enferma: 0.9999555057084821\n",
      "Predicción: enferma\n",
      "\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Supongamos que ya entrenado el modelo y el clasificador SVM (clf) entrenado y listo para usar\n",
    "# Cargar la imagen de prueba\n",
    "desired_size = (512, 512)\n",
    "\n",
    "with open('./SVC_model.pkl', 'rb') as f:\n",
    "    clf= pickle.load(f)\n",
    "image_path = \"./data/enfermas/bacterial_leaf_blight (121).JPG\"\n",
    "image = cv2.imread(image_path)\n",
    "image = cv2.resize(image, desired_size)\n",
    "\n",
    "# Preprocesar la imagen\n",
    "preprocessed_image = preprocess_image(image)\n",
    "\n",
    "# Segmentar la imagen\n",
    "_,_,segmented_image = segment_image(preprocessed_image)\n",
    "\n",
    "# Extraer características de la imagen\n",
    "features = extract_features(segmented_image)\n",
    "\n",
    "# Convertir las características en un arreglo 2D de NumPy\n",
    "X = np.array([features])\n",
    "\n",
    "# Realizar la predicción utilizando el modelo entrenado\n",
    "prediction = clf.predict(X)    \n",
    "\n",
    "# Imprimir la clase predicha\n",
    "print(\"Clase predicha:\", prediction)\n",
    "\n",
    "# Suponiendo que ya tienes tu clasificador entrenado y lo has llamado clf\n",
    "# Suponiendo también que tienes tus datos de prueba en X_test y las etiquetas verdaderas en y_true\n",
    "\n",
    "# Obtener las probabilidades de clasificación para cada clase\n",
    "probs = clf.predict_proba(X)\n",
    "\n",
    "# Obtener las predicciones de clase\n",
    "predictions = clf.predict(X)\n",
    "\n",
    "# Imprimir los resultados\n",
    "for i in range(len(X)):\n",
    "    print(f\"Muestra {i + 1}:\")\n",
    "    print(f\"Probabilidad clase sana: {probs[i][1]}\")\n",
    "    print(f\"Probabilidad clase enferma: {probs[i][0]}\")\n",
    "    print(f\"Predicción: {'sana' if predictions[i] == 1 else 'enferma'}\")\n",
    "    print()\n",
    "    print(probs[i][1]+probs[i][0])  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1cad496",
   "metadata": {},
   "source": [
    "<h1 style=\"color:RGB(0,0,255)\"> 9. Interfaz Final </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "a02a9fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Muestra 1:\n",
      "Probabilidad clase sana: 0.14505743531196585\n",
      "Probabilidad clase enferma: 0.8549425646880341\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import ImageTk, Image\n",
    "import pickle\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "desired_size = (512, 512)\n",
    "\n",
    "# Función para redimensionar la imagen a 128x128\n",
    "def resize_image(image):\n",
    "    return cv2.resize(image, (256, 256), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "# Cargar el modelo SVM previamente entrenado\n",
    "with open('./SVC_model.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)\n",
    "\n",
    "# Función para cargar y mostrar la imagen seleccionada\n",
    "test_img = []\n",
    "def load_image():\n",
    "    filepath = filedialog.askopenfilename(initialdir=\"./\", title=\"Seleccione una imagen\", filetypes=((\"Archivos de imagen\", \"*.jpg;*.jpeg;*.png\"), (\"Todos los archivos\", \"*.*\")))\n",
    "    if filepath:       \n",
    "        img = Image.open(filepath)\n",
    "        img1 = img.resize((256, 256), Image.LANCZOS)\n",
    "        img_tk = ImageTk.PhotoImage(img1)\n",
    "        #------Imagen original\n",
    "        image_labela.configure(image=img_tk)\n",
    "        image_labela.image = img_tk\n",
    "\n",
    "        # Realizar la predicción en la imagen cargada\n",
    "        img_array = np.array(img)\n",
    "        image = cv2.resize(img_array, desired_size)\n",
    "        \n",
    "        # Preprocesar la imagen\n",
    "        preprocessed_image = preprocess_image(image)         \n",
    "        # Redimensionar la imagen a 128x128\n",
    "        resized_image1 = resize_image(preprocessed_image)        \n",
    "        # Convertir la imagen de OpenCV a formato compatible con Tkinter\n",
    "        img_tk1 = ImageTk.PhotoImage(Image.fromarray(resized_image1))\n",
    "       \n",
    "        # Segmentar la imagen\n",
    "        segmented_1,segmented_2,segmented_image = segment_image(preprocessed_image)\n",
    "        # Redimensionar la imagen a 128x128----------------------------------------\n",
    "        resized_image2 = resize_image(segmented_image)  \n",
    "        # Convertir la imagen de OpenCV a formato compatible con Tkinter\n",
    "        img_tk2 = ImageTk.PhotoImage(Image.fromarray(resized_image2))                \n",
    "        #eliminacion de fondo - preprocesamiento\n",
    "        image_label1.config(image=img_tk1)\n",
    "        image_label1.image = img_tk1        \n",
    "\n",
    "        #segmented_image:enfermo -segmentar\n",
    "        image_label2.config(image=img_tk2)\n",
    "        image_label2.image = img_tk2      \n",
    "        \n",
    "        # Extraer características de la imagen\n",
    "        features = extract_features(segmented_image)\n",
    "\n",
    "        # Convertir las características en un arreglo 2D de NumPy\n",
    "        X = np.array([features])\n",
    "\n",
    "        # Realizar la predicción utilizando el modelo entrenado\n",
    "        prediction = clf.predict(X)    \n",
    "\n",
    "        # Calcula probabilidad de cada clase\n",
    "        probs = clf.predict_proba(X)\n",
    "\n",
    "        # # Imprimir la clase predicha y los resultados\n",
    "        for i in range(len(X)):\n",
    "            print(f\"Muestra {i + 1}:\")\n",
    "            print(f\"Probabilidad clase sana: {probs[i][1]}\")\n",
    "            print(f\"Probabilidad clase enferma: {probs[i][0]}\")\n",
    "            \n",
    "        prediction_label.configure(text=\"Predicción: {}\".format('SANA' if prediction[i] == 1 else 'ENFERMA'))\n",
    "#         additional_label.configure(text=\"Probabilidades:\")\n",
    "        additional_label1.configure(text=\"Enferma: {:.6f}\".format(probs[i][0]))\n",
    "        additional_label2.configure(text=\"Sana: {:.6f}\".format(probs[i][1]))\n",
    "               \n",
    "\n",
    "# Crear la ventana principal\n",
    "window = tk.Tk()\n",
    "window.title(\"PROYECTO FINAL - PEVICO\")\n",
    "#window.geometry(\"1000x800\")\n",
    "\n",
    "# Obtener el tamaño de la pantalla\n",
    "screen_width = window.winfo_screenwidth()\n",
    "screen_height = window.winfo_screenheight()\n",
    "\n",
    "# Calcular las coordenadas x e y para posicionar la ventana en el centro\n",
    "window_width = 1000  # Ancho deseado de la ventana\n",
    "window_height = 650  # Alto deseado de la ventana\n",
    "x = (screen_width - window_width) // 2\n",
    "y = (screen_height - window_height) // 2\n",
    "\n",
    "# Establecer la posición de la ventana en el centro\n",
    "window.geometry(f\"{window_width}x{window_height}+{x}+{y}\")\n",
    "\n",
    "# Cambiar el color de fondo (código hexadecimal)\n",
    "window.configure(bg=\"#FFEEDB\")\n",
    "\n",
    "#Título\n",
    "original_label0 = tk.Label(window, text=\"Identificador del Tizón bacteriano de la hoja del arroz 'Bacterial leaf blight of rice'\", font=(\"Verdana\", 15, \"bold\"), fg='#06132F',bg=\"#FFEEDB\")\n",
    "original_label0.place(relx=0.5, rely=0.05, anchor=tk.CENTER)\n",
    "#botnn\n",
    "load_button = tk.Button(window, text=\"Cargar imagen\", command=load_image, font=(\"Verdana\", 14), fg=\"white\", bg=\"blue\")\n",
    "load_button.pack(pady=65, padx=35, anchor=\"center\")  # Ajustar el espaciado vertical (5) y horizontal (20)\n",
    "\n",
    "#------------------------------------------------------------------\n",
    "original_label0 = tk.Label(window, text=\"Imagen Original                    Preprocesamiento                    Segmentación\", font=(\"Verdana\", 15, \"bold\"), fg='#06132F',bg=\"#FFEEDB\")\n",
    "original_label0.place(relx=0.5, rely=0.20, anchor=tk.CENTER)\n",
    "\n",
    "# Contenedor para las imágenes\n",
    "images_container = tk.Frame(window)\n",
    "images_container.pack(pady=10)\n",
    "\n",
    "# Crear las etiquetas para las imágenes\n",
    "image_labela = tk.Label(images_container)\n",
    "image_label1 = tk.Label(images_container)\n",
    "image_label2 = tk.Label(images_container)\n",
    "\n",
    "# Empaquetar las etiquetas de imagen una al lado de la otra\n",
    "image_labela.pack(side=tk.LEFT, padx=40)\n",
    "image_label1.pack(side=tk.LEFT, padx=40)\n",
    "image_label2.pack(side=tk.LEFT, padx=40)\n",
    "#------------------------------------------------------------------\n",
    "# Etiqueta para mostrar la imagen cargada\n",
    "original_label0 = tk.Label(window, text=\"Resultados\", font=(\"Verdana\", 15, \"bold\"), fg='black',bg=\"#FFEEDB\")\n",
    "original_label0.pack(pady=10, padx=35, anchor=\"center\")  # Espaciado y anclaje a la izquierda (Oeste)\n",
    "\n",
    "#Etiqueta para mostrar el resultado de la predicción\n",
    "prediction_label = tk.Label(window, text=\"Predicción: \" ,font=(\"Verdana\", 18, \"bold\"), fg=\"blue\", bg=\"#FFEEDB\")\n",
    "prediction_label.pack(pady=10)\n",
    "\n",
    "# additional_label = tk.Label(window, text=\"Probabilidades:\",font=(\"Verdana\", 10, \"bold\"), fg='#06132F',bg=\"#FFEEDB\")\n",
    "# additional_label.pack(pady=5)\n",
    "\n",
    "additional_label1 = tk.Label(window, text=\"Enferma:\",font=(\"Verdana\", 13, \"bold\"), fg='white',bg=\"red\")\n",
    "additional_label1.pack(pady=5)\n",
    "\n",
    "additional_label2 = tk.Label(window, text=\"Sana:\",font=(\"Verdana\", 13, \"bold\"), fg='white',bg=\"green\")\n",
    "additional_label2.pack(pady=5)\n",
    "\n",
    "# Ejecutar la aplicación\n",
    "window.mainloop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
